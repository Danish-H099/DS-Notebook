{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c95e0d0",
   "metadata": {},
   "source": [
    "# Lab1 - ANN - Big Data Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "829855eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bc69988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\91990\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d83e8e4",
   "metadata": {},
   "source": [
    "- Above code imports the necessary modules from TensorFlow for building neural networks using the Keras API.\n",
    "#### layers and models \n",
    "- modules from the tensorflow.keras package. These modules provide tools for building neural network layers and models using the Keras API.\n",
    "#### to_categorical \n",
    "- function from tensorflow.keras.utils. This function is commonly used for one-hot encoding categorical labels.\n",
    "####  Sequential class and the Dense layer \n",
    "- from the tensorflow.keras.models and tensorflow.keras.layers modules, respectively. Sequential is used to create a linear stack of layers for building neural network models, and Dense represents a fully connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b588e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"apple_quality.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca266290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A_id</th>\n",
       "      <th>Size</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Sweetness</th>\n",
       "      <th>Crunchiness</th>\n",
       "      <th>Juiciness</th>\n",
       "      <th>Ripeness</th>\n",
       "      <th>Acidity</th>\n",
       "      <th>Quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.970049</td>\n",
       "      <td>-2.512336</td>\n",
       "      <td>5.346330</td>\n",
       "      <td>-1.012009</td>\n",
       "      <td>1.844900</td>\n",
       "      <td>0.329840</td>\n",
       "      <td>-0.491590483</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.195217</td>\n",
       "      <td>-2.839257</td>\n",
       "      <td>3.664059</td>\n",
       "      <td>1.588232</td>\n",
       "      <td>0.853286</td>\n",
       "      <td>0.867530</td>\n",
       "      <td>-0.722809367</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.292024</td>\n",
       "      <td>-1.351282</td>\n",
       "      <td>-1.738429</td>\n",
       "      <td>-0.342616</td>\n",
       "      <td>2.838636</td>\n",
       "      <td>-0.038033</td>\n",
       "      <td>2.621636473</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.657196</td>\n",
       "      <td>-2.271627</td>\n",
       "      <td>1.324874</td>\n",
       "      <td>-0.097875</td>\n",
       "      <td>3.637970</td>\n",
       "      <td>-3.413761</td>\n",
       "      <td>0.790723217</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.364217</td>\n",
       "      <td>-1.296612</td>\n",
       "      <td>-0.384658</td>\n",
       "      <td>-0.553006</td>\n",
       "      <td>3.030874</td>\n",
       "      <td>-1.303849</td>\n",
       "      <td>0.501984036</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A_id      Size    Weight  Sweetness  Crunchiness  Juiciness  Ripeness  \\\n",
       "0   0.0 -3.970049 -2.512336   5.346330    -1.012009   1.844900  0.329840   \n",
       "1   1.0 -1.195217 -2.839257   3.664059     1.588232   0.853286  0.867530   \n",
       "2   2.0 -0.292024 -1.351282  -1.738429    -0.342616   2.838636 -0.038033   \n",
       "3   3.0 -0.657196 -2.271627   1.324874    -0.097875   3.637970 -3.413761   \n",
       "4   4.0  1.364217 -1.296612  -0.384658    -0.553006   3.030874 -1.303849   \n",
       "\n",
       "        Acidity Quality  \n",
       "0  -0.491590483    good  \n",
       "1  -0.722809367    good  \n",
       "2   2.621636473     bad  \n",
       "3   0.790723217    good  \n",
       "4   0.501984036    good  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f699cb2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4001, 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a39f5dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.iloc[:4000,1:-1].values\n",
    "label = df.iloc[:4000,-1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f704d7",
   "metadata": {},
   "source": [
    "Features are the input variables or attributes that are used to make predictions in a machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5107f672",
   "metadata": {},
   "source": [
    "The label, also known as the target variable or output variable, is what you are trying to predict or classify in a supervised learning problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b85c245e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.970048523 -2.512336381 5.346329613 -1.012008712 1.844900361\n",
      "  0.329839797 '-0.491590483']\n",
      " [-1.195217191 -2.839256528 3.664058758 1.588232309 0.853285795\n",
      "  0.867530082 '-0.722809367']\n",
      " [-0.292023862 -1.351281995 -1.738429162 -0.342615928 2.838635512\n",
      "  -0.038033328 '2.621636473']\n",
      " [-0.657195773 -2.271626609 1.324873847 -0.097874716 3.637970491\n",
      "  -3.413761338 '0.790723217']\n",
      " [1.36421682 -1.296611877 -0.384658206 -0.55300577 3.030874354\n",
      "  -1.303849429 '0.501984036']]\n"
     ]
    }
   ],
   "source": [
    "print(features[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5c9474f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['good' 'good' 'bad' 'good' 'good']\n"
     ]
    }
   ],
   "source": [
    "print(label[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa523c49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 7)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fac05e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a99389e",
   "metadata": {},
   "source": [
    "\n",
    "### Label encoding \n",
    "is a technique used in machine learning to convert categorical labels into numerical format. It is commonly applied to the target variable or labels in a supervised learning problem.\n",
    "The label encoder assigns a unique numerical value to each unique category in the original label set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d43f25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "target = encoder.fit_transform(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28c58a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(target[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634d7d8e",
   "metadata": {},
   "source": [
    "### train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "faf2f0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40a1c000",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(features, target, test_size=0.3, random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c80a24e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.826173149 -3.465768419 -3.391670449 0.262105904 1.473123289\n",
      "  4.24993938 '1.142108458']\n",
      " [-0.606505459 -2.1968009 -2.89354116 0.272768055 0.132270563 3.182930726\n",
      "  '0.087091587']\n",
      " [-0.302364267 1.724395847 -2.442337223 3.465108479 0.449791675\n",
      "  -0.074362452 '2.493781985']\n",
      " [1.355007604 -2.279671584 -0.499865376 0.486596383 2.179009114\n",
      "  -0.927642892 '1.775343683']\n",
      " [-4.389032417 -2.012014025 0.416052283 1.155302186 0.845483421\n",
      "  1.777485812 '5.614975313']]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b89b69",
   "metadata": {},
   "source": [
    "### Sequential Model\n",
    "A sequential model in Keras is a linear stack of layers where you can simply add one layer at a time. Each layer has weights that correspond to the layer that follows it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6fe552f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\91990\\anaconda3\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define a sequential model\n",
    "model = Sequential([\n",
    "    # First hidden layer with 6 units, ReLU activation function, and input dimension of 7\n",
    "    # Input Dim is 7 because we have 7 column of features.\n",
    "    Dense(6, activation='relu', input_dim=7),\n",
    "    \n",
    "    # Second hidden layer with 8 units and ReLU activation function\n",
    "    Dense(8, activation='relu'),\n",
    "    \n",
    "    # Output layer with 1 unit and sigmoid activation function (for binary classification)\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb57f494",
   "metadata": {},
   "source": [
    "#### optimizer=\"adam\": \n",
    "This specifies the Adam optimization algorithm, which is a popular choice for gradient-based optimization.\n",
    "#### loss='binary_crossentropy': \n",
    "This is the loss function used for binary classification problems. It measures the difference between the true labels and the predicted probabilities.\n",
    "#### metrics=['accuracy']: \n",
    "During training, the model will monitor accuracy as an evaluation metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49e52e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\91990\\anaconda3\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 6)                 48        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 56        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 113 (452.00 Byte)\n",
      "Trainable params: 113 (452.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdf0532",
   "metadata": {},
   "source": [
    "printed a summary of your model's architecture, showing the number of parameters in each layer. The summary includes information about the layers, the output shapes, and the number of parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0eea4ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.asarray(x_train).astype(np.float32)\n",
    "y_train  = np.asarray(y_train).astype(np.float32)\n",
    "x_test = np.asarray(x_test).astype(np.float32)\n",
    "y_test  = np.asarray(y_test).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb702cd",
   "metadata": {},
   "source": [
    "converting your training and testing data to NumPy arrays and explicitly specifying the data type as np.float32. This is a common preprocessing step before feeding the data into a machine learning model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8384e56",
   "metadata": {},
   "source": [
    "#### fit()\n",
    "- fit method trains the model on the training data (x_train and y_train) for the specified number of epochs, and it validates the model on the provided validation data at the end of each epoch. \n",
    "- The training process updates the model's weights based on the chosen optimization algorithm and the specified loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b02feb7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\91990\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\91990\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "88/88 [==============================] - 2s 5ms/step - loss: 0.6640 - accuracy: 0.6029 - val_loss: 0.6324 - val_accuracy: 0.6575\n",
      "Epoch 2/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.6008 - accuracy: 0.6893 - val_loss: 0.5863 - val_accuracy: 0.7042\n",
      "Epoch 3/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.5499 - accuracy: 0.7382 - val_loss: 0.5387 - val_accuracy: 0.7417\n",
      "Epoch 4/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7657 - val_loss: 0.5036 - val_accuracy: 0.7608\n",
      "Epoch 5/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.4726 - accuracy: 0.7846 - val_loss: 0.4774 - val_accuracy: 0.7733\n",
      "Epoch 6/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.4512 - accuracy: 0.7914 - val_loss: 0.4604 - val_accuracy: 0.7758\n",
      "Epoch 7/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.4357 - accuracy: 0.7954 - val_loss: 0.4477 - val_accuracy: 0.7858\n",
      "Epoch 8/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.4243 - accuracy: 0.8025 - val_loss: 0.4380 - val_accuracy: 0.7900\n",
      "Epoch 9/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.4150 - accuracy: 0.8089 - val_loss: 0.4300 - val_accuracy: 0.7942\n",
      "Epoch 10/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.4077 - accuracy: 0.8104 - val_loss: 0.4239 - val_accuracy: 0.7983\n",
      "Epoch 11/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.4009 - accuracy: 0.8136 - val_loss: 0.4164 - val_accuracy: 0.8033\n",
      "Epoch 12/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3943 - accuracy: 0.8171 - val_loss: 0.4116 - val_accuracy: 0.8075\n",
      "Epoch 13/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.3895 - accuracy: 0.8204 - val_loss: 0.4059 - val_accuracy: 0.8067\n",
      "Epoch 14/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.3850 - accuracy: 0.8254 - val_loss: 0.4017 - val_accuracy: 0.8058\n",
      "Epoch 15/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.3803 - accuracy: 0.8250 - val_loss: 0.3968 - val_accuracy: 0.8108\n",
      "Epoch 16/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.3764 - accuracy: 0.8257 - val_loss: 0.3943 - val_accuracy: 0.8133\n",
      "Epoch 17/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.3725 - accuracy: 0.8293 - val_loss: 0.3895 - val_accuracy: 0.8200\n",
      "Epoch 18/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.3700 - accuracy: 0.8293 - val_loss: 0.3854 - val_accuracy: 0.8208\n",
      "Epoch 19/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.3668 - accuracy: 0.8293 - val_loss: 0.3825 - val_accuracy: 0.8233\n",
      "Epoch 20/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.3639 - accuracy: 0.8350 - val_loss: 0.3794 - val_accuracy: 0.8250\n",
      "Epoch 21/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.3608 - accuracy: 0.8296 - val_loss: 0.3762 - val_accuracy: 0.8300\n",
      "Epoch 22/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.3585 - accuracy: 0.8343 - val_loss: 0.3743 - val_accuracy: 0.8258\n",
      "Epoch 23/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.3562 - accuracy: 0.8375 - val_loss: 0.3707 - val_accuracy: 0.8367\n",
      "Epoch 24/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.3537 - accuracy: 0.8379 - val_loss: 0.3679 - val_accuracy: 0.8350\n",
      "Epoch 25/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.3515 - accuracy: 0.8411 - val_loss: 0.3660 - val_accuracy: 0.8400\n",
      "Epoch 26/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.3495 - accuracy: 0.8386 - val_loss: 0.3652 - val_accuracy: 0.8400\n",
      "Epoch 27/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.3468 - accuracy: 0.8393 - val_loss: 0.3622 - val_accuracy: 0.8350\n",
      "Epoch 28/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.3441 - accuracy: 0.8404 - val_loss: 0.3589 - val_accuracy: 0.8425\n",
      "Epoch 29/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.3422 - accuracy: 0.8454 - val_loss: 0.3566 - val_accuracy: 0.8400\n",
      "Epoch 30/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.3393 - accuracy: 0.8439 - val_loss: 0.3542 - val_accuracy: 0.8475\n",
      "Epoch 31/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.3356 - accuracy: 0.8471 - val_loss: 0.3518 - val_accuracy: 0.8458\n",
      "Epoch 32/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.3323 - accuracy: 0.8486 - val_loss: 0.3506 - val_accuracy: 0.8475\n",
      "Epoch 33/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.3291 - accuracy: 0.8536 - val_loss: 0.3474 - val_accuracy: 0.8483\n",
      "Epoch 34/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.3257 - accuracy: 0.8543 - val_loss: 0.3429 - val_accuracy: 0.8475\n",
      "Epoch 35/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.3217 - accuracy: 0.8614 - val_loss: 0.3403 - val_accuracy: 0.8458\n",
      "Epoch 36/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.3184 - accuracy: 0.8593 - val_loss: 0.3370 - val_accuracy: 0.8492\n",
      "Epoch 37/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.3154 - accuracy: 0.8636 - val_loss: 0.3350 - val_accuracy: 0.8500\n",
      "Epoch 38/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.3120 - accuracy: 0.8643 - val_loss: 0.3313 - val_accuracy: 0.8550\n",
      "Epoch 39/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.3096 - accuracy: 0.8696 - val_loss: 0.3299 - val_accuracy: 0.8525\n",
      "Epoch 40/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.3065 - accuracy: 0.8689 - val_loss: 0.3264 - val_accuracy: 0.8592\n",
      "Epoch 41/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.3039 - accuracy: 0.8721 - val_loss: 0.3225 - val_accuracy: 0.8600\n",
      "Epoch 42/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.3014 - accuracy: 0.8732 - val_loss: 0.3211 - val_accuracy: 0.8600\n",
      "Epoch 43/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.2988 - accuracy: 0.8789 - val_loss: 0.3166 - val_accuracy: 0.8642\n",
      "Epoch 44/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.2954 - accuracy: 0.8771 - val_loss: 0.3161 - val_accuracy: 0.8650\n",
      "Epoch 45/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.2932 - accuracy: 0.8768 - val_loss: 0.3120 - val_accuracy: 0.8733\n",
      "Epoch 46/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.2918 - accuracy: 0.8789 - val_loss: 0.3093 - val_accuracy: 0.8708\n",
      "Epoch 47/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.2883 - accuracy: 0.8804 - val_loss: 0.3061 - val_accuracy: 0.8742\n",
      "Epoch 48/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.2857 - accuracy: 0.8821 - val_loss: 0.3041 - val_accuracy: 0.8733\n",
      "Epoch 49/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.2833 - accuracy: 0.8821 - val_loss: 0.3009 - val_accuracy: 0.8783\n",
      "Epoch 50/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.2804 - accuracy: 0.8825 - val_loss: 0.2992 - val_accuracy: 0.8800\n",
      "Epoch 51/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.2778 - accuracy: 0.8814 - val_loss: 0.2963 - val_accuracy: 0.8817\n",
      "Epoch 52/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.2768 - accuracy: 0.8829 - val_loss: 0.2938 - val_accuracy: 0.8825\n",
      "Epoch 53/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.2734 - accuracy: 0.8832 - val_loss: 0.2928 - val_accuracy: 0.8842\n",
      "Epoch 54/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.2711 - accuracy: 0.8850 - val_loss: 0.2900 - val_accuracy: 0.8850\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 3ms/step - loss: 0.2689 - accuracy: 0.8854 - val_loss: 0.2905 - val_accuracy: 0.8850\n",
      "Epoch 56/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.2658 - accuracy: 0.8875 - val_loss: 0.2863 - val_accuracy: 0.8883\n",
      "Epoch 57/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.2638 - accuracy: 0.8900 - val_loss: 0.2846 - val_accuracy: 0.8875\n",
      "Epoch 58/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.2607 - accuracy: 0.8893 - val_loss: 0.2820 - val_accuracy: 0.8942\n",
      "Epoch 59/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.2579 - accuracy: 0.8914 - val_loss: 0.2783 - val_accuracy: 0.8958\n",
      "Epoch 60/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.2556 - accuracy: 0.8914 - val_loss: 0.2760 - val_accuracy: 0.8950\n",
      "Epoch 61/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.2527 - accuracy: 0.8954 - val_loss: 0.2738 - val_accuracy: 0.8967\n",
      "Epoch 62/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.2497 - accuracy: 0.8971 - val_loss: 0.2707 - val_accuracy: 0.9008\n",
      "Epoch 63/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.2475 - accuracy: 0.8968 - val_loss: 0.2694 - val_accuracy: 0.9000\n",
      "Epoch 64/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.2455 - accuracy: 0.8971 - val_loss: 0.2709 - val_accuracy: 0.9042\n",
      "Epoch 65/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.2438 - accuracy: 0.8993 - val_loss: 0.2648 - val_accuracy: 0.9067\n",
      "Epoch 66/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.2413 - accuracy: 0.9004 - val_loss: 0.2639 - val_accuracy: 0.9042\n",
      "Epoch 67/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.2394 - accuracy: 0.9014 - val_loss: 0.2625 - val_accuracy: 0.9075\n",
      "Epoch 68/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.2379 - accuracy: 0.9018 - val_loss: 0.2597 - val_accuracy: 0.9058\n",
      "Epoch 69/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.2365 - accuracy: 0.9036 - val_loss: 0.2590 - val_accuracy: 0.9100\n",
      "Epoch 70/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.2342 - accuracy: 0.9039 - val_loss: 0.2603 - val_accuracy: 0.9075\n",
      "Epoch 71/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.2327 - accuracy: 0.9054 - val_loss: 0.2595 - val_accuracy: 0.9067\n",
      "Epoch 72/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.2309 - accuracy: 0.9057 - val_loss: 0.2538 - val_accuracy: 0.9083\n",
      "Epoch 73/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.2298 - accuracy: 0.9057 - val_loss: 0.2530 - val_accuracy: 0.9083\n",
      "Epoch 74/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.2283 - accuracy: 0.9096 - val_loss: 0.2519 - val_accuracy: 0.9083\n",
      "Epoch 75/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.2265 - accuracy: 0.9079 - val_loss: 0.2513 - val_accuracy: 0.9117\n",
      "Epoch 76/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.2249 - accuracy: 0.9089 - val_loss: 0.2485 - val_accuracy: 0.9125\n",
      "Epoch 77/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.2242 - accuracy: 0.9089 - val_loss: 0.2487 - val_accuracy: 0.9100\n",
      "Epoch 78/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.2225 - accuracy: 0.9111 - val_loss: 0.2488 - val_accuracy: 0.9117\n",
      "Epoch 79/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.2217 - accuracy: 0.9118 - val_loss: 0.2473 - val_accuracy: 0.9167\n",
      "Epoch 80/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.2203 - accuracy: 0.9132 - val_loss: 0.2487 - val_accuracy: 0.9150\n",
      "Epoch 81/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.2186 - accuracy: 0.9125 - val_loss: 0.2454 - val_accuracy: 0.9150\n",
      "Epoch 82/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.2179 - accuracy: 0.9143 - val_loss: 0.2462 - val_accuracy: 0.9175\n",
      "Epoch 83/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.2165 - accuracy: 0.9136 - val_loss: 0.2438 - val_accuracy: 0.9167\n",
      "Epoch 84/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.2168 - accuracy: 0.9168 - val_loss: 0.2459 - val_accuracy: 0.9150\n",
      "Epoch 85/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.2139 - accuracy: 0.9175 - val_loss: 0.2420 - val_accuracy: 0.9167\n",
      "Epoch 86/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.2149 - accuracy: 0.9171 - val_loss: 0.2442 - val_accuracy: 0.9183\n",
      "Epoch 87/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.2124 - accuracy: 0.9157 - val_loss: 0.2424 - val_accuracy: 0.9183\n",
      "Epoch 88/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.2117 - accuracy: 0.9164 - val_loss: 0.2406 - val_accuracy: 0.9217\n",
      "Epoch 89/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.2105 - accuracy: 0.9171 - val_loss: 0.2426 - val_accuracy: 0.9175\n",
      "Epoch 90/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.2091 - accuracy: 0.9171 - val_loss: 0.2408 - val_accuracy: 0.9158\n",
      "Epoch 91/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.2081 - accuracy: 0.9186 - val_loss: 0.2399 - val_accuracy: 0.9192\n",
      "Epoch 92/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.2073 - accuracy: 0.9193 - val_loss: 0.2389 - val_accuracy: 0.9183\n",
      "Epoch 93/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.2057 - accuracy: 0.9218 - val_loss: 0.2382 - val_accuracy: 0.9192\n",
      "Epoch 94/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.2051 - accuracy: 0.9232 - val_loss: 0.2385 - val_accuracy: 0.9192\n",
      "Epoch 95/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.2037 - accuracy: 0.9204 - val_loss: 0.2355 - val_accuracy: 0.9183\n",
      "Epoch 96/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.2022 - accuracy: 0.9232 - val_loss: 0.2366 - val_accuracy: 0.9175\n",
      "Epoch 97/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.2012 - accuracy: 0.9239 - val_loss: 0.2360 - val_accuracy: 0.9217\n",
      "Epoch 98/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.1995 - accuracy: 0.9236 - val_loss: 0.2338 - val_accuracy: 0.9192\n",
      "Epoch 99/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.1979 - accuracy: 0.9225 - val_loss: 0.2361 - val_accuracy: 0.9233\n",
      "Epoch 100/100\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.1980 - accuracy: 0.9239 - val_loss: 0.2323 - val_accuracy: 0.9225\n"
     ]
    }
   ],
   "source": [
    "final = model.fit(x_train, y_train, epochs = 100, validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c21f61d",
   "metadata": {},
   "source": [
    "The final variable likely stores information about the training process, such as loss and accuracy values over epochs. You can use this information to analyze the model's performance and make decisions about further training or model adjustments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbbf6be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
